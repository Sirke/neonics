geom_point(data= coef, aes(coefficient, Estimate)) + geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), colour ='red', width=0.4)+ theme(axis.text.x = element_text(angle = 90))+
geom_hline(yintercept=0,linetype="dashed")
ggplot() +
geom_point(data= coef, aes(coefficient, Estimate)) + geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), colour ='red', width=0.2)+ theme(axis.text.x = element_text(angle = 90))+
geom_hline(yintercept=0,linetype="dashed")
ggplot() +
geom_point(data= coef, aes(coefficient, Estimate)) + geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2)+ theme(axis.text.x = element_text(angle = 90))+
geom_hline(yintercept=0,linetype="dashed")
coef$signi=ifelse(coef$p >= 0.04 , 'N', 'Y')
coef
coef$signi=ifelse(coef$p >= 0.03 , 'N', 'Y')
coef
ggplot() +
geom_point(data= coef, aes(coefficient, Estimate,fill=signi)) + geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2)+ theme(axis.text.x = element_text(angle = 90))+
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi),size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
coef$signi=factor(ifelse(coef$p >= 0.03 , 'N', 'Y'))
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
###########################################################################
#mallit glmmadmb-funktiolla
#mallit
M1=glmmadmb(terri ~ year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M2=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M3=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region + NeoPrior*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M4=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region  + temp*year + prec*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M5=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region + shanG*year + open*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M6=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region + NeoPrior*year + shanG*year + open*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M7=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region + NeoPrior*year + temp*year + prec*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M8=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region + shanG*year + open*year + temp*year + prec*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
M9=glmmadmb(terri ~ year + Abuild + Aroad + Astream + Ariver + agri5 + region + NeoPrior*year + shanG*year + open*year + temp*year + prec*year
+ offset(Larea)
+ (1 + year| id),
family="nbinom2",
data=dataS)
#Malli N9 on globaalimalli, joka sisältää kaiken.
#sen summarya tutkailemalla voi huomata jo nyt, jos malli olisi ihan päin honkia.
summary(M9)
output<-model.sel(M1,M2,M3,M4,M5,M6,M7,M8,M9)
output
AIC(M1,M2,M3,M4,M5,M6,M7,M8,M9)
topmodels = get.models(output,cumsum(weight)<=0.95)
aver=model.avg(topmodels, revised.var = TRUE, fit=TRUE)
summary(aver)
coef(aver)
confint(aver)
#taulukkoa taas yritän tehdä..
m_coefs <- coefTable(aver, full=T, adjust.se = TRUE) #full=T tarkoittaa, että estimaatit on arvioitu full average menetelmällä vs. conditional average, joita käytin käsintehdyissä ennusteissa.
coefnames <- row.names(m_coefs)
m_coefs <- as.data.frame(m_coefs)
m_coefs <- mutate(m_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(m_coefs, digits = 2)
coefs=m_coef
coefs$coefficient=factor(coefs$coefficient)
coefs$signi=factor(ifelse(coefs$p >= 0.03 , 'N', 'Y'))
coefs=m_coefs
coefs$coefficient=factor(coefs$coefficient)
coefs$signi=factor(ifelse(coefs$p >= 0.03 , 'N', 'Y'))
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
coefs
summary(aver)
output<-model.sel(M1,M2,M3,M4,M5,M6,M7,M8,M9)
output
AIC(M1,M2,M3,M4,M5,M6,M7,M8,M9)
topmodels = get.models(output,cumsum(weight)<=0.95)
aver=model.avg(topmodels, revised.var = TRUE, fit=TRUE)
summary(aver)
#taulukkoa taas yritän tehdä..
m_coefs <- coefTable(aver, full=T, adjust.se = TRUE) #full=T tarkoittaa, että estimaatit on arvioitu full average menetelmällä vs. conditional average, joita käytin käsintehdyissä ennusteissa.
m_coefs
coefnames <- row.names(m_coefs)
m_coefs <- as.data.frame(m_coefs)
m_coefs <- mutate(m_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(m_coefs, digits = 2)
coefs=m_coefs
coefs$coefficient=factor(coefs$coefficient)
coefs$signi=factor(ifelse(coefs$p >= 0.03 , 'N', 'Y'))
knitr::kable(m_coefs, digits = 2)
knitr::kable(coefs, digits = 2)
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
#Malli N9 on globaalimalli, joka sisältää kaiken.
#sen summarya tutkailemalla voi huomata jo nyt, jos malli olisi ihan päin honkia.
summary(M9)
output<-model.sel(M1,M2,M3,M4,M5,M6,M7,M8,M9)
output
AIC(M1,M2,M3,M4,M5,M6,M7,M8,M9)
topmodels = get.models(output,cumsum(weight)<=0.95)
aver=model.avg(topmodels, revised.var = TRUE, fit=TRUE)
summary(aver)
coef(aver)
confint(aver)
#taulukkoa taas yritän tehdä..
m_coefs <- coefTable(aver, full=T, adjust.se = TRUE) #full=T tarkoittaa, että estimaatit on arvioitu full average menetelmällä vs. conditional average, joita käytin käsintehdyissä ennusteissa. 'SE' on tässä nimenomaan adjusted SE.
coefnames <- row.names(m_coefs)
m_coefs <- as.data.frame(m_coefs)
m_coefs <- mutate(m_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(m_coefs, digits = 2)
coefs=m_coefs
coefs$coefficient=factor(coefs$coefficient)
coefs$signi=factor(ifelse(coefs$p >= 0.03 , 'N', 'Y'))
knitr::kable(coefs, digits = 2)
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
#taulukkoa taas yritän tehdä..
m_coefs <- coefTable(aver, full=F, adjust.se = TRUE) #full=T tarkoittaa, että estimaatit on arvioitu full average menetelmällä vs. conditional average, joita käytin käsintehdyissä ennusteissa. 'SE' on tässä nimenomaan adjusted SE.
coefnames <- row.names(m_coefs)
m_coefs <- as.data.frame(m_coefs)
m_coefs <- mutate(m_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(m_coefs, digits = 2)
coefs=m_coefs
coefs$coefficient=factor(coefs$coefficient)
coefs$signi=factor(ifelse(coefs$p >= 0.03 , 'N', 'Y'))
knitr::kable(coefs, digits = 2)
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coefs, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coefs, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
#predictions
newdata <- expand.grid(NeoPrior= with(dataS, seq(0.1, 0.9, length.out=3)),
year = mean(dataS$year),
Abuild = mean(dataS$Abuild),
Aroad = mean(dataS$Aroad),
Astream = mean(dataS$Astream),
Ariver = mean(dataS$Ariver),
agri5 = mean(dataS$agri5),
region = levels(dataS$region),
temp = mean(dataS$temp),
prec = mean(dataS$prec),
Larea=mean(dataS$Larea)) #näissä ennusteissa on mukana pinta-ala offsetti, vrt. käsintehtyihin ennusteisiin
pred.se <- predict(aver, type="link", re.form=NA,se.fit=TRUE, full=T, newdata)
#nämä ennusteet lasketaan nyt full averaged eikä conditional arvoista. Varmaan sen takia tulokset hieman erilaiset?
newdata$fit <- pred.se$fit
newdata$SE <- pred.se$se
newdata$upr=newdata$fit+1.96*newdata$SE
newdata$lwr=newdata$fit-1.96*newdata$SE
newdata$fitX <-exp(newdata$fit)
newdata$SEX<-exp(newdata$SE)
newdata$uprX=exp(newdata$upr)
newdata$lwrX=  exp(newdata$lwr)
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.35))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
View(newdata)
newdata$region <- factor(newdata$region, levels = c('POH', 'LOU', 'UUS', 'ETH'))
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.35))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
newdata$region <- factor(newdata$region, levels = c('POH', 'UUS', 'LOU', 'ETH'))
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.35))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
newdata$NeoPrior=as.character(newdata$NeoPrior)
newdata$NeoPrior=revalue(newdata$NeoPrior,c("0.1"="low","0.5"="med","0.9"="high"))
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.35))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
newdata$NeoPrior <- factor(newdata$NeoPrior, levels = c('low', 'med', 'high'))
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.35))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.1))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
ggplot(newdata, aes(x=NeoPrior, y=fitX, fill=region)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=lwrX, ymax=uprX), width=.1, position=position_dodge(0.9))+labs(title="ennustettu reviirien määrä", x = "öljykasvien osuus", y = "ennustettu reviirien määrä")
#Malli N9 on globaalimalli, joka sisältää kaiken.
#sen summarya tutkailemalla voi huomata jo nyt, jos malli olisi ihan päin honkia.
summary(N9)
#tarkistetaan ettei globaalimalli ole ylidispersoitunut
E2 <- resid(N9, type = "pearson")
N  <- nrow(dataS)
p  <- length(fixef(N9)$con) + 3  #2 sigmas and 1 size/k/theta NB parameter
sum(E2^2) / (N - p)
#globaalimalli on hieman alidispersoitunut, 0.74, onko tämä ongelma?
#How good is the model performing?
F9 <- fitted(N9)
par(mfrow = c(1,1), cex.lab = 1.5, mar = c(5,5,2,2))
plot(x = dataS$terri,
y = F9,
xlab = "Fitted values (with re)",
ylab = "Number of territories",
xlim = c(0,15),
ylim = c(0,15))
abline(h = 0, lty = 2)
cor(dataS$terri, F9)
#rankataan kaikki mallit niiden AICc arvoon perustuen. Mitä pienempi arvo sen parempi.
#AICc arvo arvioi mallien laadukkuutta suhteessa toisiinsa, se ei sinänsä kerro mitään siitä, onko yksikään malleista sopiva
#tutkijan on etukäteen pitänyt miettiä, että näissä malleissa on järkeä
output1<-model.sel(N1,N2,N3,N4,N5,N6,N7,N8,N9)
output1
#taulukkoa yritin tehdä..
knitr::kable(output1, digits = 2)
#paras malli on N7 mutta vain 0.23 AICc-yksikön päässä on toiseksi paras malli N4, joka olisi yksinkertaisempi ja melkein yhtä hyvä
#yksinkertaisuus on yleensä kaunista mutta silloin meidän mielenkiinnon kohteena oleva NeoPrior tippuisi pois tarkastelusta
#valitaan useampi paras malli ja haetaan niistä kompromissia
#tarkistan, onko tuloksissa eroa jos vertailisinkin AIC-arvoja. AICc arvo on korjattu huomioimaan pieni otoskoko.
#Meillähän on aineistoa riittävästi, eli periaatteessa AICc arvon sijaan voisi käyttää AIC:täkin.
AIC(N1,N2,N3,N4,N5,N6,N7,N8,N9)
#ei eroa, samat kaksi mallia valikoituisivat jatkoon. Näillä mennään.
#valitaan jatkoon parhaimmat mallit, joilla alhaisimmat AICc-arvot, kriteerinä usein käytetty AICcdelta<4
#topmodels = get.models(output1,subset=delta<4)
#jatkoon valikoituu vain kaksi mallia
#tämä olisi vaihtoehtoinen kriteeri valita "parhaimmat" mallit, niiden "painoarvon" perusteella
topmodels = get.models(output1,cumsum(weight)<=0.95)
#tällä valinnalla mukaan tulisi kolme parasta mallia
#tehdään "parhaimmille" malleille model averaging eli käytetään useampaa (kahta) mallia muuttujien
#estimaattien (vaikutuksen) arviointiin.
ave=model.avg(topmodels, revised.var = TRUE, fit=TRUE)
summary(ave)
#Tästä taulukosta katsotaan conditional average-arvoja (tällä menetelmällä muuttujan estimaatti arvioidaan vain
#niistä malleista, joissa se esiintyy). Estimaatit NeoPrior-muuttujalle eroavat hieman averaging metodien välillä
#(full average metodissa muuttujan estimaatti arvioidaan kaikista malleista mutta niissä malleissa missä muuttujaa
#ei ole (eli N4) se saa arvon nolla).
#tässä siis eri muuttujille vielä kerran estimaatit (regressiokerroinko tämä on suomeksi?:)
coef(ave)
#ja niille luottamusvälit
confint(ave)
#jos luottamusvälien sisälle mahtuu nolla, ei muuttuja ole "merkitsevä", tai siis sen vaikutus on pieni eikä edes sen
#merkkiä (negatiivinen vai positiivinen) pysty arvioimaan luotettavasti.
#year, Ariver, agri5, region, NeoPrior ja  temp selittävät osansa reviirien määrän vaihtelusta
#taulukkoa taas yritän tehdä..
ma_coefs <- coefTable(ave, full=F, adjust.se = TRUE)
coefnames <- row.names(ma_coefs)
ma_coefs <- as.data.frame(ma_coefs)
ma_coefs <- mutate(ma_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(ma_coefs, digits = 2)
coef=ma_coefs
coef$coefficient=factor(coef$coefficient)
coef$signi=factor(ifelse(coef$p >= 0.04 , 'N', 'Y'))
lapply(paketit,library,character.only=T)
#Malli N9 on globaalimalli, joka sisältää kaiken.
#sen summarya tutkailemalla voi huomata jo nyt, jos malli olisi ihan päin honkia.
summary(N9)
#tarkistetaan ettei globaalimalli ole ylidispersoitunut
E2 <- resid(N9, type = "pearson")
N  <- nrow(dataS)
p  <- length(fixef(N9)$con) + 3  #2 sigmas and 1 size/k/theta NB parameter
sum(E2^2) / (N - p)
#globaalimalli on hieman alidispersoitunut, 0.74, onko tämä ongelma?
#How good is the model performing?
F9 <- fitted(N9)
par(mfrow = c(1,1), cex.lab = 1.5, mar = c(5,5,2,2))
plot(x = dataS$terri,
y = F9,
xlab = "Fitted values (with re)",
ylab = "Number of territories",
xlim = c(0,15),
ylim = c(0,15))
abline(h = 0, lty = 2)
cor(dataS$terri, F9)
#rankataan kaikki mallit niiden AICc arvoon perustuen. Mitä pienempi arvo sen parempi.
#AICc arvo arvioi mallien laadukkuutta suhteessa toisiinsa, se ei sinänsä kerro mitään siitä, onko yksikään malleista sopiva
#tutkijan on etukäteen pitänyt miettiä, että näissä malleissa on järkeä
output1<-model.sel(N1,N2,N3,N4,N5,N6,N7,N8,N9)
output1
#taulukkoa yritin tehdä..
knitr::kable(output1, digits = 2)
#paras malli on N7 mutta vain 0.23 AICc-yksikön päässä on toiseksi paras malli N4, joka olisi yksinkertaisempi ja melkein yhtä hyvä
#yksinkertaisuus on yleensä kaunista mutta silloin meidän mielenkiinnon kohteena oleva NeoPrior tippuisi pois tarkastelusta
#valitaan useampi paras malli ja haetaan niistä kompromissia
#tarkistan, onko tuloksissa eroa jos vertailisinkin AIC-arvoja. AICc arvo on korjattu huomioimaan pieni otoskoko.
#Meillähän on aineistoa riittävästi, eli periaatteessa AICc arvon sijaan voisi käyttää AIC:täkin.
AIC(N1,N2,N3,N4,N5,N6,N7,N8,N9)
#ei eroa, samat kaksi mallia valikoituisivat jatkoon. Näillä mennään.
#valitaan jatkoon parhaimmat mallit, joilla alhaisimmat AICc-arvot, kriteerinä usein käytetty AICcdelta<4
#topmodels = get.models(output1,subset=delta<4)
#jatkoon valikoituu vain kaksi mallia
#tämä olisi vaihtoehtoinen kriteeri valita "parhaimmat" mallit, niiden "painoarvon" perusteella
topmodels = get.models(output1,cumsum(weight)<=0.95)
#tällä valinnalla mukaan tulisi kolme parasta mallia
#tehdään "parhaimmille" malleille model averaging eli käytetään useampaa (kahta) mallia muuttujien
#estimaattien (vaikutuksen) arviointiin.
ave=model.avg(topmodels, revised.var = TRUE, fit=TRUE)
summary(ave)
#Tästä taulukosta katsotaan conditional average-arvoja (tällä menetelmällä muuttujan estimaatti arvioidaan vain
#niistä malleista, joissa se esiintyy). Estimaatit NeoPrior-muuttujalle eroavat hieman averaging metodien välillä
#(full average metodissa muuttujan estimaatti arvioidaan kaikista malleista mutta niissä malleissa missä muuttujaa
#ei ole (eli N4) se saa arvon nolla).
#tässä siis eri muuttujille vielä kerran estimaatit (regressiokerroinko tämä on suomeksi?:)
coef(ave)
#ja niille luottamusvälit
confint(ave)
#jos luottamusvälien sisälle mahtuu nolla, ei muuttuja ole "merkitsevä", tai siis sen vaikutus on pieni eikä edes sen
#merkkiä (negatiivinen vai positiivinen) pysty arvioimaan luotettavasti.
#year, Ariver, agri5, region, NeoPrior ja  temp selittävät osansa reviirien määrän vaihtelusta
#taulukkoa taas yritän tehdä..
ma_coefs <- coefTable(ave, full=F, adjust.se = TRUE)
coefnames <- row.names(ma_coefs)
ma_coefs <- as.data.frame(ma_coefs)
ma_coefs <- mutate(ma_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(ma_coefs, digits = 2)
coef=ma_coefs
coef$coefficient=factor(coef$coefficient)
coef$signi=factor(ifelse(coef$p >= 0.04 , 'N', 'Y'))
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
#Malli N9 on globaalimalli, joka sisältää kaiken.
#sen summarya tutkailemalla voi huomata jo nyt, jos malli olisi ihan päin honkia.
summary(N9)
#tarkistetaan ettei globaalimalli ole ylidispersoitunut
E2 <- resid(N9, type = "pearson")
N  <- nrow(dataS)
p  <- length(fixef(N9)$con) + 3  #2 sigmas and 1 size/k/theta NB parameter
sum(E2^2) / (N - p)
#globaalimalli on hieman alidispersoitunut, 0.74, onko tämä ongelma?
#How good is the model performing?
F9 <- fitted(N9)
par(mfrow = c(1,1), cex.lab = 1.5, mar = c(5,5,2,2))
plot(x = dataS$terri,
y = F9,
xlab = "Fitted values (with re)",
ylab = "Number of territories",
xlim = c(0,15),
ylim = c(0,15))
abline(h = 0, lty = 2)
cor(dataS$terri, F9)
#rankataan kaikki mallit niiden AICc arvoon perustuen. Mitä pienempi arvo sen parempi.
#AICc arvo arvioi mallien laadukkuutta suhteessa toisiinsa, se ei sinänsä kerro mitään siitä, onko yksikään malleista sopiva
#tutkijan on etukäteen pitänyt miettiä, että näissä malleissa on järkeä
output1<-model.sel(N1,N2,N3,N4,N5,N6,N7,N8,N9)
output1
#taulukkoa yritin tehdä..
knitr::kable(output1, digits = 2)
#paras malli on N7 mutta vain 0.23 AICc-yksikön päässä on toiseksi paras malli N4, joka olisi yksinkertaisempi ja melkein yhtä hyvä
#yksinkertaisuus on yleensä kaunista mutta silloin meidän mielenkiinnon kohteena oleva NeoPrior tippuisi pois tarkastelusta
#valitaan useampi paras malli ja haetaan niistä kompromissia
#tarkistan, onko tuloksissa eroa jos vertailisinkin AIC-arvoja. AICc arvo on korjattu huomioimaan pieni otoskoko.
#Meillähän on aineistoa riittävästi, eli periaatteessa AICc arvon sijaan voisi käyttää AIC:täkin.
AIC(N1,N2,N3,N4,N5,N6,N7,N8,N9)
#ei eroa, samat kaksi mallia valikoituisivat jatkoon. Näillä mennään.
#valitaan jatkoon parhaimmat mallit, joilla alhaisimmat AICc-arvot, kriteerinä usein käytetty AICcdelta<4
#topmodels = get.models(output1,subset=delta<4)
#jatkoon valikoituu vain kaksi mallia
#tämä olisi vaihtoehtoinen kriteeri valita "parhaimmat" mallit, niiden "painoarvon" perusteella
topmodels = get.models(output1,cumsum(weight)<=0.95)
#tällä valinnalla mukaan tulisi kolme parasta mallia
#tehdään "parhaimmille" malleille model averaging eli käytetään useampaa (kahta) mallia muuttujien
#estimaattien (vaikutuksen) arviointiin.
ave=model.avg(topmodels, revised.var = TRUE, fit=TRUE)
summary(ave)
#Tästä taulukosta katsotaan conditional average-arvoja (tällä menetelmällä muuttujan estimaatti arvioidaan vain
#niistä malleista, joissa se esiintyy). Estimaatit NeoPrior-muuttujalle eroavat hieman averaging metodien välillä
#(full average metodissa muuttujan estimaatti arvioidaan kaikista malleista mutta niissä malleissa missä muuttujaa
#ei ole (eli N4) se saa arvon nolla).
#tässä siis eri muuttujille vielä kerran estimaatit (regressiokerroinko tämä on suomeksi?:)
coef(ave)
#ja niille luottamusvälit
confint(ave)
#jos luottamusvälien sisälle mahtuu nolla, ei muuttuja ole "merkitsevä", tai siis sen vaikutus on pieni eikä edes sen
#merkkiä (negatiivinen vai positiivinen) pysty arvioimaan luotettavasti.
#year, Ariver, agri5, region, NeoPrior ja  temp selittävät osansa reviirien määrän vaihtelusta
#taulukkoa taas yritän tehdä..
ma_coefs <- coefTable(ave, full=F, adjust.se = TRUE)
coefnames <- row.names(ma_coefs)
ma_coefs <- as.data.frame(ma_coefs)
ma_coefs <- mutate(ma_coefs,
coefficient = coefnames,
t = Estimate / `Std. Error`,
p = pt(abs(t), df = 1397, lower.tail = FALSE), #en tiedä onko df oikein. Mutta sen muuttaminen ei muuta tuloksia?!
lower95 = Estimate - 1.96 * `Std. Error`,
upper95 = Estimate + 1.96 * `Std. Error`) %>% select(coefficient, Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(ma_coefs, digits = 2)
coef=ma_coefs
coef$coefficient=factor(coef$coefficient)
coef$signi=factor(ifelse(coef$p >= 0.035 , 'N', 'Y'))
ggplot(data= coef, aes(coefficient, Estimate,group=signi)) +
geom_point(aes(shape=signi), size=2) + scale_shape_manual(values=c(1,16)) +
geom_errorbar(data = coef, aes(coefficient, Estimate, ymin=lower95, ymax = upper95), width=0.2) +
theme(axis.text.x = element_text(angle = 90)) +
geom_hline(yintercept=0,linetype="dashed")
lapply(paketit,library,character.only=T)
#predictions
newdata <- expand.grid(NeoPrior= with(dataS, seq(0.1, 0.9, length.out=3)),
year = mean(dataS$year),
Abuild = mean(dataS$Abuild),
Aroad = mean(dataS$Aroad),
Astream = mean(dataS$Astream),
Ariver = mean(dataS$Ariver),
agri5 = mean(dataS$agri5),
region = levels(dataS$region),
temp = mean(dataS$temp),
prec = mean(dataS$prec),
Larea=mean(dataS$Larea)) #näissä ennusteissa on mukana pinta-ala offsetti, vrt. käsintehtyihin ennusteisiin
pred.se <- predict(aver, type="link", re.form=NA,se.fit=TRUE, full=T, newdata)
newdata$fit <- pred.se$fit
newdata$SE <- pred.se$se
newdata$upr=newdata$fit+1.96*newdata$SE
newdata$lwr=newdata$fit-1.96*newdata$SE
newdata$fitX <-exp(newdata$fit)
newdata$SEX<-exp(newdata$SE)
newdata$uprX=exp(newdata$upr)
newdata$lwrX=  exp(newdata$lwr)
newdata
range(dataS$Larea)
range(data$area)
log(0.19)
